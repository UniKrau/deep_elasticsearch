# 1、一个糟糕的设计

https://elasticsearch.cn/question/10827

场景是静态化查询字段+动态关系过滤的问题

由于es无法支持我的关系查询的需要，所以我需要将静态字段查询用es实现（因为字段非常的多，很多是来源于不同的表聚合出来的进=静态字段），动态关系查询用mysql实现，最后将es和mysql的结果集取交集，最后分页。
 
请问有没有什么比较好的实现方案？两个一起使用后运算感觉问题很大?

回复：

这就是糟糕的设计，以后肯定是灾难。

# 2、EQL 不支持哪些操作

PowerShell下如下的运行语句（出于隐私目的，没写出ip和端口）:
 curl.exe -X GET "x.x.x.x:x/_sql" -H 'Content-Type: application/json' -d"SELECT none_pay_course_list FROM user_portrayal where uc_id=4001464" ;
 
运行结果：
{"took":33,"timed_out":false,"_shards":{"total":6,"successful":6,"skipped":0,"failed":0},"hits":{"total":{"value":1,"relation":"eq"},"max_score":0.0,"hits":[{"_index":"user_portrayal","_type":"_doc","_id":"4001464_1","_score":0.0,"_source":{"none_pay_course_list":[{"course":"11_30"},{"course":"11_37"},{"course":"11_23"},{"course":"11_38"}]}}]}}
 
提出问题：
如何改写运行语句，使得能够计算出none_pay_course_list的数组中元素个数。此处目测正确答案为4.（本人试过了split,count,size,length等各种各样的组合，但是还是未得到正确的答案，望得到解答，十分感谢）

直接看官方回复：

https://www.elastic.co/guide/en/elasticsearch/reference/current/eql-syntax.html#eql-syntax-limitations

# 3、ES udpate upsert性能如何优化？

https://elasticsearch.cn/question/10881

ES版本5.6，数据量在3000万左右，数据更新频率比较频繁，总共的更新速度大概是1w/s-5w/s。
最新的数据先进kafka，再由flink消费写入ES。

目前发现在默认的ES配置下，bulk update或者upsert的速度始终上不去，所有节点的cpu使用率才25%左右，速度最高只能到1w/s左右。

如果改成这些数据全部是插入，不做更新操作，那么cpu可以跑满，而且kafka的消费绝对没有积压。

试过增加节点，效果很小，速度看起来有一点点的增加。试过增加分片数，有效果，但仍然不是很明显。
 
请问是什么原因导致这个现象呢，增加分片对写入速度有提升又是为什么呢？

像这种场景，有没有办法直接的提升update/upsert速率，或者间接解决，比如全部用插入的方式写入，查询时同一个id的记录取时间最近的数据。那么查询方式还有删除旧数据这块怎么设计比较好

【精彩回复】

- 1.update是先get再insert然后再delete（标记删除）旧的文档，和insert相比，肯定update耗时多

- 2.由于一次操作完成时长多，线程池数量有限，导致cpu只有25%（猜测...）

- 3.适当增加ES分片，对写入是有一点提高，因为相当于多出来了lucene进程，可以接收的请求多了，付出的代价就是分片多了之后同步数据是需要消耗性能的，然后查询更是会性能降低
- 4.客户端使用层面：可以全部使用insert提高性能，然后定时去delete，定时（低峰期）合并segment，优化数据结构
- 5.集群本身层面：可以控制refresh的频率，translog设置，副本可以先干掉（写完再补回来），线程池参数修改-------这些都是危险操作，评估后再进行实践

在上面基础上补充：
- 1. 使用ES自动的id，不要指定id
- 2. 提高操作系统 filesystem cache
- 3. 关注下 index_buffer_size 这个参数

# 4、排序优先级

如何查询置顶商品并排序？

问题表述:
- 搜索电商商品,后台运营将商品标志为是否置顶,
- 如果这个商品被标志为置顶商品(is_ontop),在查询的时候,
- 使其排在最前面.同时先按照销量排序,
- 如何销量相同再按照商品上架时间来编写怎么编写dsl语句

【基础解决方案】
```
GET  index/_search
{
    "from": 0,
    "size": 10,
    "query": {
        "function_score": {
            "query": {
                "bool": {
                    "should": [{
                        "constant_score": {
                            "filter": {
                                "match": {
                                    "sk": {
                                        "query": "耐克"
                                    }
                                }
                            }
                        }
                    }]
                }
            }
        }
    },
    "sort": [{
            "is_ontop": {
                "order": "desc"
            }
        }, {
            "saleCount": {
                "order": "desc"
            }
        },
        {
            "saleTime": {
                "order": "desc"
            }
        }
    ]
}
```
sort排序中，排在前面的优先级高，后面的优先级低，当前一个的值相同时，才会根据后一个排序。

is_ontop 排第一位，优先排置顶的，当is_ontop 相同时，才会根据saleCount降序，以此类推。

【新功能解决方案】

新版本有一个类似置顶的查询，可以先将置顶的查出来完后用这个查询就会排在最前面。

使用：Pinned Query

- Pinned： 就是固定的意思。
- Pinned Query 精准含义：

提升所选文档的排名，使其高于与给定查询匹配的文档。

此功能通常用于引导搜索者查找精选的文档，这些文档在搜索的任何“有机”匹配项之上被提升。 使用存储在_id字段中的文档ID来标识升级或“固定”的文档。

Demo 举例：

```
GET /_search
{
  "query": {
    "pinned": {
      "ids": [ "1", "4", "100" ],
      "organic": {
        "match": {
          "description": "iphone"
        }
      }
    }
  }
}
```

# 5、CCR(跨集群复制) 订阅集群会与 领导集群数据完全相同么？

现公司想实现一个场景：

A  生产集群，对外提供服务，时效是2个月，每天滚动删除60天前的数据

B 备份集群，同步生产集群的数据，时效是6个月，每天滚动删除180天前的数据

使用CCR来从A同步到B可以么？

或者说A被删除的数据会不会也同步在B删除呢？

如果同步删除的话，还有没有快照之外的其他方式来实现前面的业务场景呢，请大神给个思路

【Medcl 回复】

CCR 可以实现索引的同步，生命周期可以在两个集群分开管理。

A 集群和 B 集群的索引处于同步状态的话是不能被删的。需要先解除同步关系。如果是日志场景，都是新增的数据，可以在 Rollover 之后使用 Unfollow 来自动解除同步关系。

# 6、es怎么能通过一个同义词获得其他所有的同义词

我搜索时匹配到同义词的某个词，我想把它所有的同义词都找出来，用java api可以实现吗，现在能想到的就是去读txt文本，有更好的方法吗？

【回复】
可以借助： analyzer API 实现。

# 7、closed index 如何漂移

【问题】

现在有个 ES 集群, 有20台左右的物理机. 现在要将其中的3台物理机下线.但是其中有许多 closed indices. 

如何只让要下线的3台物理机里的 indices(包括 closed indices) 漂移到其他机器上.  

【核心实现】
```
PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.exclude._ip": "192.168.0.1,192.168.0.2,192.168.0.3"
  }
}
```

首先停止往要下掉的节点分配，

使用cluster.routing.allocation.exclude._ip或者cluster.routing.allocation.exclude._name
 
然后通过监控api确认分片都自动迁移到其它节点后，停掉旧节点服务。

# 8、搜索字段长度大于2的数据

版本v7.9.2，字段是keyword类型，以下是文档中看到的方法，执行没有报错也没有数据返回，还有一些更老的写法我就不贴了

```
如果你要进行筛选操作，你可以使用 filter
DELETE test_index

PUT test_index
{
  "mappings": {
    "properties": {
      "name":{
        "type": "keyword"
      }
    }
  }
}

POST test_index/_bulk
{"index":{"_id":1}}
{"name":"BKing"}
{"index":{"_id":2}}
{"name":"Tom"}
{"index":{"_id":3}}
{"name":"Steven"}
{"index":{"_id":3}}
{"name":"Kn"}
{"index":{"_id":4}}
{"name":"M"}
{"index":{"_id":5}}
{"name":"Jack Smith"}

GET /test_index/_search

POST test_index/_search
{
  "query": {
    "bool": {
      "filter": [
        {
          "script": {
            "script": {
              "lang": "painless",
              "source": "doc['name'].value.length() >= 2 && doc['name'].value.length() <= 5"
            }
          }
        }
      ]
    }
  }
}

```



